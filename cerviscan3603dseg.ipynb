{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "Some Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-02T09:37:54.603741Z",
     "iopub.status.idle": "2023-07-02T09:37:54.604678Z",
     "shell.execute_reply": "2023-07-02T09:37:54.604240Z",
     "shell.execute_reply.started": "2023-07-02T09:37:54.604186Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip -q install monai\n",
    "!pip -q install segmentation-models-pytorch==0.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-02T09:37:54.606265Z",
     "iopub.status.idle": "2023-07-02T09:37:54.607088Z",
     "shell.execute_reply": "2023-07-02T09:37:54.606796Z",
     "shell.execute_reply.started": "2023-07-02T09:37:54.606773Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip -q install pylibjpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-02T09:37:54.608705Z",
     "iopub.status.idle": "2023-07-02T09:37:54.609405Z",
     "shell.execute_reply": "2023-07-02T09:37:54.609177Z",
     "shell.execute_reply.started": "2023-07-02T09:37:54.609155Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip -q install gdcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-02T09:37:54.611303Z",
     "iopub.status.idle": "2023-07-02T09:37:54.611989Z",
     "shell.execute_reply": "2023-07-02T09:37:54.611781Z",
     "shell.execute_reply.started": "2023-07-02T09:37:54.611759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydicom"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading pydicom-2.4.1-py3-none-any.whl (1.8 MB)\n",
      "     ---------------------------------------- 1.8/1.8 MB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: pydicom\n",
      "Successfully installed pydicom-2.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydicom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-02T09:38:01.403753Z",
     "iopub.status.idle": "2023-07-02T09:38:01.404769Z",
     "shell.execute_reply": "2023-07-02T09:38:01.404520Z",
     "shell.execute_reply.started": "2023-07-02T09:38:01.404482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nibabel\n",
      "  Downloading nibabel-5.1.0-py3-none-any.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=17 in c:\\users\\root\\anaconda3\\lib\\site-packages (from nibabel) (20.9)\n",
      "Collecting importlib-resources>=1.3\n",
      "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\root\\anaconda3\\lib\\site-packages (from nibabel) (1.20.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\root\\anaconda3\\lib\\site-packages (from importlib-resources>=1.3->nibabel) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\root\\anaconda3\\lib\\site-packages (from packaging>=17->nibabel) (2.4.7)\n",
      "Installing collected packages: importlib-resources, nibabel\n",
      "Successfully installed importlib-resources-5.12.0 nibabel-5.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Downloading albumentations-1.3.1-py3-none-any.whl (125 kB)\n",
      "     ------------------------------------ 125.7/125.7 kB 923.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML in c:\\users\\root\\anaconda3\\lib\\site-packages (from albumentations) (5.4.1)\n",
      "Collecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in c:\\users\\root\\anaconda3\\lib\\site-packages (from albumentations) (0.18.1)\n",
      "Requirement already satisfied: numpy>=1.11.1 in c:\\users\\root\\anaconda3\\lib\\site-packages (from albumentations) (1.20.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\root\\anaconda3\\lib\\site-packages (from albumentations) (1.6.2)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-win_amd64.whl (38.0 MB)\n",
      "     ---------------------------------------- 38.0/38.0 MB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\root\\anaconda3\\lib\\site-packages (from qudida>=0.0.4->albumentations) (0.24.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\root\\anaconda3\\lib\\site-packages (from qudida>=0.0.4->albumentations) (3.7.4.3)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\root\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (3.3.4)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\root\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in c:\\users\\root\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (8.2.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\root\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\root\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2021.4.8)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\root\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\root\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\root\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\root\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\root\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.10.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\root\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (5.0.6)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\root\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\root\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (2.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\root\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n",
      "Installing collected packages: opencv-python-headless, qudida, albumentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Accès refusé: 'c:\\\\users\\\\root\\\\anaconda3\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-02T09:38:14.180013Z",
     "iopub.status.busy": "2023-07-02T09:38:14.179646Z",
     "iopub.status.idle": "2023-07-02T09:38:14.185615Z",
     "shell.execute_reply": "2023-07-02T09:38:14.184223Z",
     "shell.execute_reply.started": "2023-07-02T09:38:14.179983Z"
    }
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path = [\n",
    "    '../input/covn3d-same',\n",
    "] + sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'albumentations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-644155693597>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0malbumentations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpylab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'albumentations'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import ast\n",
    "import cv2\n",
    "import time\n",
    "import timm\n",
    "import pickle\n",
    "import random\n",
    "import pydicom\n",
    "import argparse\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import albumentations\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from monai.transforms import Resize\n",
    "import  monai.transforms as transforms\n",
    "\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 20, 8\n",
    "device = torch.device('cuda')\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T09:38:20.904788Z",
     "iopub.status.busy": "2023-07-02T09:38:20.904388Z",
     "iopub.status.idle": "2023-07-02T09:38:20.948884Z",
     "shell.execute_reply": "2023-07-02T09:38:20.946551Z",
     "shell.execute_reply.started": "2023-07-02T09:38:20.904758Z"
    }
   },
   "outputs": [],
   "source": [
    "from monai.transforms import Resize\n",
    "kernel_type = 'timm3d_res18d_unet4b_128_128_128_dsv2_flip12_shift333p7_gd1p5_bs4_lr3e4_20x50ep'\n",
    "load_kernel = None\n",
    "load_last = True\n",
    "n_blocks = 4\n",
    "n_folds = 5\n",
    "backbone = 'resnet18d'\n",
    "\n",
    "image_sizes = [128, 128, 128]\n",
    "R = Resize(image_sizes)\n",
    "\n",
    "init_lr = 3e-3\n",
    "batch_size = 4\n",
    "drop_rate = 0.\n",
    "drop_path_rate = 0.\n",
    "loss_weights = [1, 1]\n",
    "p_mixup = 0.1\n",
    "\n",
    "base_path = '../input/rsna-2022-cervical-spine-fracture-detection'\n",
    "use_amp = True\n",
    "num_workers = 4\n",
    "out_dim = 7\n",
    "\n",
    "n_epochs = 1000\n",
    "\n",
    "log_dir = './logs'\n",
    "model_dir = './models'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-02T09:38:01.392306Z",
     "iopub.status.idle": "2023-07-02T09:38:01.392675Z",
     "shell.execute_reply": "2023-07-02T09:38:01.392521Z",
     "shell.execute_reply.started": "2023-07-02T09:38:01.392505Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/rsna-2022-cervical-spine-fracture-detection\\\\train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-3f433ac220e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbase_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"../input/rsna-2022-cervical-spine-fracture-detection\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmask_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{base_path}/segmentations'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m df_mask = pd.DataFrame({\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/rsna-2022-cervical-spine-fracture-detection\\\\train.csv'"
     ]
    }
   ],
   "source": [
    "base_path = \"../input/rsna-2022-cervical-spine-fracture-detection\"\n",
    "df_train = pd.read_csv(os.path.join(base_path, 'train.csv'))\n",
    "\n",
    "mask_files = os.listdir(f'{base_path}/segmentations')\n",
    "df_mask = pd.DataFrame({\n",
    "    'mask_file': mask_files,\n",
    "})\n",
    "df_mask['StudyInstanceUID'] = df_mask['mask_file'].apply(lambda x: x[:-4])\n",
    "df_mask['mask_file'] = df_mask['mask_file'].apply(lambda x: os.path.join(base_path, 'segmentations', x))\n",
    "df = df_train.merge(df_mask, on='StudyInstanceUID', how='left')\n",
    "df['image_folder'] = df['StudyInstanceUID'].apply(lambda x: os.path.join(base_path, 'train_images', x))\n",
    "df['mask_file'].fillna('', inplace=True)\n",
    "\n",
    "df_seg = df.query('mask_file != \"\"').reset_index(drop=True)\n",
    "\n",
    "kf = KFold(5)\n",
    "df_seg['fold'] = -1\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(df_seg, df_seg)):\n",
    "    df_seg.loc[valid_idx, 'fold'] = fold\n",
    "\n",
    "df_seg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-02T09:38:01.394198Z",
     "iopub.status.idle": "2023-07-02T09:38:01.395275Z",
     "shell.execute_reply": "2023-07-02T09:38:01.395021Z",
     "shell.execute_reply.started": "2023-07-02T09:38:01.394982Z"
    }
   },
   "outputs": [],
   "source": [
    "revert_list = [\n",
    "    '1.2.826.0.1.3680043.1363',\n",
    "    '1.2.826.0.1.3680043.20120',\n",
    "    '1.2.826.0.1.3680043.2243',\n",
    "    '1.2.826.0.1.3680043.24606',\n",
    "    '1.2.826.0.1.3680043.32071'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-02T09:38:01.397113Z",
     "iopub.status.idle": "2023-07-02T09:38:01.397798Z",
     "shell.execute_reply": "2023-07-02T09:38:01.397581Z",
     "shell.execute_reply.started": "2023-07-02T09:38:01.397560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def load_dicom(path):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    data = dicom.pixel_array\n",
    "    data = cv2.resize(data, (image_sizes[0], image_sizes[1]), interpolation = cv2.INTER_LINEAR)\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_dicom_line_par(path):\n",
    "\n",
    "    t_paths = sorted(glob(os.path.join(path, \"*\")),\n",
    "       key=lambda x: int(x.split('/')[-1].split(\".\")[0]))\n",
    "\n",
    "    n_scans = len(t_paths)\n",
    "    indices = np.quantile(list(range(n_scans)), np.linspace(0., 1., image_sizes[2])).round().astype(int)\n",
    "    t_paths = [t_paths[i] for i in indices]\n",
    "\n",
    "    images = []\n",
    "    for filename in t_paths:\n",
    "        images.append(load_dicom(filename))\n",
    "    images = np.stack(images, -1)\n",
    "    \n",
    "    images = images - np.min(images)\n",
    "    images = images / (np.max(images) + 1e-4)\n",
    "    images = (images * 255).astype(np.uint8)\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def load_sample(row, has_mask=True):\n",
    "\n",
    "    image = load_dicom_line_par(row.image_folder)\n",
    "    if image.ndim < 4:\n",
    "        image = np.expand_dims(image, 0).repeat(3, 0)  # to 3ch\n",
    "\n",
    "    if has_mask:\n",
    "        mask_org = nib.load(row.mask_file).get_fdata()\n",
    "        shape = mask_org.shape\n",
    "        mask_org = mask_org.transpose(1, 0, 2)[::-1, :, ::-1]  # (d, w, h)\n",
    "        mask = np.zeros((7, shape[0], shape[1], shape[2]))\n",
    "        for cid in range(7):\n",
    "            mask[cid] = (mask_org == (cid+1))\n",
    "        mask = mask.astype(np.uint8) * 255\n",
    "        mask = R(mask).numpy()\n",
    "        \n",
    "        return image, mask\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "\n",
    "\n",
    "class SEGDataset(Dataset):\n",
    "    def __init__(self, df, mode, transform):\n",
    "\n",
    "        self.df = df.reset_index()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        image, mask = load_sample(row, has_mask=True)\n",
    "    \n",
    "        if row.StudyInstanceUID in revert_list:\n",
    "            mask = mask[:, :, :, ::-1]\n",
    "\n",
    "        res = self.transform({'image':image, 'mask':mask})\n",
    "        image = res['image'] / 255.\n",
    "        mask = res['mask']\n",
    "        mask = (mask > 127).astype(np.float32)\n",
    "\n",
    "        image, mask = torch.tensor(image).float(), torch.tensor(mask).float()\n",
    "\n",
    "        return image, mask\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-02T09:38:01.399310Z",
     "iopub.status.idle": "2023-07-02T09:38:01.400159Z",
     "shell.execute_reply": "2023-07-02T09:38:01.399949Z",
     "shell.execute_reply.started": "2023-07-02T09:38:01.399921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from monai.transforms import Resize\n",
    "import  monai.transforms as transforms\n",
    "\n",
    "image_sizes = [128, 128, 128]\n",
    "R = Resize(image_sizes)\n",
    "\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.RandFlipd(keys=[\"image\", \"mask\"], prob=0.5, spatial_axis=1),\n",
    "    transforms.RandFlipd(keys=[\"image\", \"mask\"], prob=0.5, spatial_axis=2),\n",
    "    transforms.RandAffined(keys=[\"image\", \"mask\"], translate_range=[int(x*y) for x, y in zip(image_sizes, [0.3, 0.3, 0.3])], padding_mode='zeros', prob=0.7),\n",
    "    transforms.RandGridDistortiond(keys=(\"image\", \"mask\"), prob=0.5, distort_limit=(-0.01, 0.01), mode=\"nearest\"),    \n",
    "])\n",
    "\n",
    "transforms_valid = transforms.Compose([\n",
    "])\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-02T09:38:01.401535Z",
     "iopub.status.idle": "2023-07-02T09:38:01.402554Z",
     "shell.execute_reply": "2023-07-02T09:38:01.402319Z",
     "shell.execute_reply.started": "2023-07-02T09:38:01.402296Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_seg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-c13974d85df3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'figure.figsize'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf_show\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_seg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdataset_show\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSEGDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_show\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransforms_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'done'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_seg' is not defined"
     ]
    }
   ],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20,8\n",
    "\n",
    "df_show = df_seg\n",
    "dataset_show = SEGDataset(df_show, 'train', transform=transforms_train)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-02T09:38:01.406257Z",
     "iopub.status.idle": "2023-07-02T09:38:01.406850Z",
     "shell.execute_reply": "2023-07-02T09:38:01.406643Z",
     "shell.execute_reply.started": "2023-07-02T09:38:01.406622Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "for i in range(2):\n",
    "    f, axarr = plt.subplots(1,4)\n",
    "    for p in range(4):\n",
    "        idx = i*4+p\n",
    "        img, mask = dataset_show[idx]\n",
    "        img = img[:, :, :, 60]\n",
    "        mask = mask[:, :, :, 60]\n",
    "        mask[0] = mask[0] + mask[3] + mask[6]\n",
    "        mask[1] = mask[1] + mask[4]\n",
    "        mask[2] = mask[2] + mask[5]\n",
    "        mask = mask[:3]\n",
    "        img = img * 0.7 + mask * 0.3\n",
    "\n",
    "        axarr[p].imshow(img.transpose(0, 1).transpose(1,2).squeeze())\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-02T09:38:01.408473Z",
     "iopub.status.idle": "2023-07-02T09:38:01.409484Z",
     "shell.execute_reply": "2023-07-02T09:38:01.409268Z",
     "shell.execute_reply.started": "2023-07-02T09:38:01.409247Z"
    }
   },
   "outputs": [],
   "source": [
    "class TimmSegModel(nn.Module):\n",
    "    def __init__(self, backbone, segtype='unet', pretrained=False):\n",
    "        super(TimmSegModel, self).__init__()\n",
    "\n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=3,\n",
    "            features_only=True,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "        g = self.encoder(torch.rand(1, 3, 64, 64))\n",
    "        encoder_channels = [1] + [_.shape[1] for _ in g]\n",
    "        decoder_channels = [256, 128, 64, 32, 16]\n",
    "        if segtype == 'unet':\n",
    "            self.decoder = smp.unet.decoder.UnetDecoder(\n",
    "                encoder_channels=encoder_channels[:n_blocks+1],\n",
    "                decoder_channels=decoder_channels[:n_blocks],\n",
    "                n_blocks=n_blocks,\n",
    "            )\n",
    "\n",
    "        self.segmentation_head = nn.Conv2d(decoder_channels[n_blocks-1], out_dim, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        global_features = [0] + self.encoder(x)[:n_blocks]\n",
    "        seg_features = self.decoder(*global_features)\n",
    "        seg_features = self.segmentation_head(seg_features)\n",
    "        return seg_features\n",
    "    \n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-02T09:38:01.410774Z",
     "iopub.status.idle": "2023-07-02T09:38:01.411410Z",
     "shell.execute_reply": "2023-07-02T09:38:01.411168Z",
     "shell.execute_reply.started": "2023-07-02T09:38:01.411147Z"
    }
   },
   "outputs": [],
   "source": [
    "from timm.models.layers.conv2d_same import Conv2dSame\n",
    "from conv3d_same import Conv3dSame\n",
    "import time\n",
    "import timm\n",
    "import pickle\n",
    "import random\n",
    "import pydicom\n",
    "import segmentation_models_pytorch as smp\n",
    "n_blocks = 4\n",
    "drop_rate = 0.\n",
    "backbone = 'resnet18d'\n",
    "drop_path_rate = 0.\n",
    "out_dim = 7\n",
    "\n",
    "def convert_3d(module):\n",
    "\n",
    "    module_output = module\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        module_output = torch.nn.BatchNorm3d(\n",
    "            module.num_features,\n",
    "            module.eps,\n",
    "            module.momentum,\n",
    "            module.affine,\n",
    "            module.track_running_stats,\n",
    "        )\n",
    "        if module.affine:\n",
    "            with torch.no_grad():\n",
    "                module_output.weight = module.weight\n",
    "                module_output.bias = module.bias\n",
    "        module_output.running_mean = module.running_mean\n",
    "        module_output.running_var = module.running_var\n",
    "        module_output.num_batches_tracked = module.num_batches_tracked\n",
    "        if hasattr(module, \"qconfig\"):\n",
    "            module_output.qconfig = module.qconfig\n",
    "            \n",
    "    elif isinstance(module, Conv2dSame):\n",
    "        module_output = Conv3dSame(\n",
    "            in_channels=module.in_channels,\n",
    "            out_channels=module.out_channels,\n",
    "            kernel_size=module.kernel_size[0],\n",
    "            stride=module.stride[0],\n",
    "            padding=module.padding[0],\n",
    "            dilation=module.dilation[0],\n",
    "            groups=module.groups,\n",
    "            bias=module.bias is not None,\n",
    "        )\n",
    "        module_output.weight = torch.nn.Parameter(module.weight.unsqueeze(-1).repeat(1,1,1,1,module.kernel_size[0]))\n",
    "\n",
    "    elif isinstance(module, torch.nn.Conv2d):\n",
    "        module_output = torch.nn.Conv3d(\n",
    "            in_channels=module.in_channels,\n",
    "            out_channels=module.out_channels,\n",
    "            kernel_size=module.kernel_size[0],\n",
    "            stride=module.stride[0],\n",
    "            padding=module.padding[0],\n",
    "            dilation=module.dilation[0],\n",
    "            groups=module.groups,\n",
    "            bias=module.bias is not None,\n",
    "            padding_mode=module.padding_mode\n",
    "        )\n",
    "        module_output.weight = torch.nn.Parameter(module.weight.unsqueeze(-1).repeat(1,1,1,1,module.kernel_size[0]))\n",
    "\n",
    "    elif isinstance(module, torch.nn.MaxPool2d):\n",
    "        module_output = torch.nn.MaxPool3d(\n",
    "            kernel_size=module.kernel_size,\n",
    "            stride=module.stride,\n",
    "            padding=module.padding,\n",
    "            dilation=module.dilation,\n",
    "            ceil_mode=module.ceil_mode,\n",
    "        )\n",
    "    elif isinstance(module, torch.nn.AvgPool2d):\n",
    "        module_output = torch.nn.AvgPool3d(\n",
    "            kernel_size=module.kernel_size,\n",
    "            stride=module.stride,\n",
    "            padding=module.padding,\n",
    "            ceil_mode=module.ceil_mode,\n",
    "        )\n",
    "\n",
    "    for name, child in module.named_children():\n",
    "        module_output.add_module(\n",
    "            name, convert_3d(child)\n",
    "        )\n",
    "    del module\n",
    "\n",
    "    return module_output\n",
    "\n",
    "\n",
    "m = TimmSegModel(backbone)\n",
    "m = convert_3d(m)\n",
    "m(torch.rand(1, 3, 128,128,128)).shape\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-02T09:38:01.412889Z",
     "iopub.status.idle": "2023-07-02T09:38:01.413768Z",
     "shell.execute_reply": "2023-07-02T09:38:01.413558Z",
     "shell.execute_reply.started": "2023-07-02T09:38:01.413537Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional\n",
    "\n",
    "loss_weights = [1, 1]\n",
    "\n",
    "def binary_dice_score(\n",
    "    y_pred: torch.Tensor,\n",
    "    y_true: torch.Tensor,\n",
    "    threshold: Optional[float] = None,\n",
    "    nan_score_on_empty=False,\n",
    "    eps: float = 1e-7,\n",
    ") -> float:\n",
    "\n",
    "    if threshold is not None:\n",
    "        y_pred = (y_pred > threshold).to(y_true.dtype)\n",
    "\n",
    "    intersection = torch.sum(y_pred * y_true).item()\n",
    "    cardinality = (torch.sum(y_pred) + torch.sum(y_true)).item()\n",
    "\n",
    "    score = (2.0 * intersection) / (cardinality + eps)\n",
    "\n",
    "    has_targets = torch.sum(y_true) > 0\n",
    "    has_predicted = torch.sum(y_pred) > 0\n",
    "\n",
    "    if not has_targets:\n",
    "        if nan_score_on_empty:\n",
    "            score = np.nan\n",
    "        else:\n",
    "            score = float(not has_predicted)\n",
    "    return score\n",
    "\n",
    "\n",
    "def multilabel_dice_score(\n",
    "    y_true: torch.Tensor,\n",
    "    y_pred: torch.Tensor,\n",
    "    threshold=None,\n",
    "    eps=1e-7,\n",
    "    nan_score_on_empty=False,\n",
    "):\n",
    "    ious = []\n",
    "    num_classes = y_pred.size(0)\n",
    "    for class_index in range(num_classes):\n",
    "        iou = binary_dice_score(\n",
    "            y_pred=y_pred[class_index],\n",
    "            y_true=y_true[class_index],\n",
    "            threshold=threshold,\n",
    "            nan_score_on_empty=nan_score_on_empty,\n",
    "            eps=eps,\n",
    "        )\n",
    "        ious.append(iou)\n",
    "\n",
    "    return ious\n",
    "\n",
    "\n",
    "def dice_loss(input, target):\n",
    "    input = torch.sigmoid(input)\n",
    "    smooth = 1.0\n",
    "    iflat = input.view(-1)\n",
    "    tflat = target.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    return 1 - ((2.0 * intersection + smooth) / (iflat.sum() + tflat.sum() + smooth))\n",
    "\n",
    "\n",
    "def bce_dice(input, target, loss_weights=loss_weights):\n",
    "    loss1 = loss_weights[0] * nn.BCEWithLogitsLoss()(input, target)\n",
    "    loss2 = loss_weights[1] * dice_loss(input, target)\n",
    "    return (loss1 + loss2) / sum(loss_weights)\n",
    "\n",
    "criterion = bce_dice\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-02T09:38:01.415348Z",
     "iopub.status.idle": "2023-07-02T09:38:01.416047Z",
     "shell.execute_reply": "2023-07-02T09:38:01.415796Z",
     "shell.execute_reply.started": "2023-07-02T09:38:01.415771Z"
    }
   },
   "outputs": [],
   "source": [
    "def mixup(input, truth, clip=[0, 1]):\n",
    "    indices = torch.randperm(input.size(0))\n",
    "    shuffled_input = input[indices]\n",
    "    shuffled_labels = truth[indices]\n",
    "\n",
    "    lam = np.random.uniform(clip[0], clip[1])\n",
    "    input = input * lam + shuffled_input * (1 - lam)\n",
    "    return input, truth, shuffled_labels, lam\n",
    "\n",
    "\n",
    "def train_func(model, loader_train, optimizer, scaler=None):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    bar = tqdm(loader_train)\n",
    "    for images, gt_masks in bar:\n",
    "        optimizer.zero_grad()\n",
    "        images = images.cuda()\n",
    "        gt_masks = gt_masks.cuda()\n",
    "\n",
    "        do_mixup = False\n",
    "        if random.random() < p_mixup:\n",
    "            do_mixup = True\n",
    "            images, gt_masks, gt_masks_sfl, lam = mixup(images, gt_masks)\n",
    "\n",
    "        with amp.autocast():\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, gt_masks)\n",
    "            if do_mixup:\n",
    "                loss2 = criterion(logits, gt_masks_sfl)\n",
    "                loss = loss * lam  + loss2 * (1 - lam)\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        bar.set_description(f'smth:{np.mean(train_loss[-30:]):.4f}')\n",
    "\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "\n",
    "def valid_func(model, loader_valid):\n",
    "    model.eval()\n",
    "    valid_loss = []\n",
    "    outputs = []\n",
    "    ths = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "    batch_metrics = [[]] * 7\n",
    "    bar = tqdm(loader_valid)\n",
    "    with torch.no_grad():\n",
    "        for images, gt_masks in bar:\n",
    "            images = images.cuda()\n",
    "            gt_masks = gt_masks.cuda()\n",
    "\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, gt_masks)\n",
    "            valid_loss.append(loss.item())\n",
    "            for thi, th in enumerate(ths):\n",
    "                pred = (logits.sigmoid() > th).float().detach()\n",
    "                for i in range(logits.shape[0]):\n",
    "                    tmp = multilabel_dice_score(\n",
    "                        y_pred=logits[i].sigmoid().cpu(),\n",
    "                        y_true=gt_masks[i].cpu(),\n",
    "                        threshold=0.5,\n",
    "                    )\n",
    "                    batch_metrics[thi].extend(tmp)\n",
    "            bar.set_description(f'smth:{np.mean(valid_loss[-30:]):.4f}')\n",
    "            \n",
    "    metrics = [np.mean(this_metric) for this_metric in batch_metrics]\n",
    "    print('best th:', ths[np.argmax(metrics)], 'best dc:', np.max(metrics))\n",
    "\n",
    "    return np.mean(valid_loss), np.max(metrics)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-02T09:38:01.419082Z",
     "iopub.status.idle": "2023-07-02T09:38:01.419958Z",
     "shell.execute_reply": "2023-07-02T09:38:01.419794Z",
     "shell.execute_reply.started": "2023-07-02T09:38:01.419776Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(fold):\n",
    "\n",
    "    log_file = os.path.join(log_dir, f'{kernel_type}.txt')\n",
    "    model_file = os.path.join(model_dir, f'{kernel_type}_fold{fold}_best.pth')\n",
    "\n",
    "    train_ = df_seg[df_seg['fold'] != fold].reset_index(drop=True)\n",
    "    valid_ = df_seg[df_seg['fold'] == fold].reset_index(drop=True)\n",
    "    dataset_train = SEGDataset(train_, 'train', transform=transforms_train)\n",
    "    dataset_valid = SEGDataset(valid_, 'valid', transform=transforms_valid)\n",
    "    loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    loader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    model = TimmSegModel(backbone, pretrained=True)\n",
    "    model = convert_3d(model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=init_lr)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    from_epoch = 0\n",
    "    metric_best = 0.\n",
    "    loss_min = np.inf\n",
    "\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, n_epochs)\n",
    "\n",
    "    print(len(dataset_train), len(dataset_valid))\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        scheduler_cosine.step(epoch-1)\n",
    "\n",
    "        print(time.ctime(), 'Epoch:', epoch)\n",
    "\n",
    "        train_loss = train_func(model, loader_train, optimizer, scaler)\n",
    "        valid_loss, metric = valid_func(model, loader_valid)\n",
    "\n",
    "        content = time.ctime() + ' ' + f'Fold {fold}, Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {train_loss:.5f}, valid loss: {valid_loss:.5f}, metric: {(metric):.6f}.'\n",
    "        print(content)\n",
    "        with open(log_file, 'a') as appender:\n",
    "            appender.write(content + '\\n')\n",
    "\n",
    "        if metric > metric_best:\n",
    "            print(f'metric_best ({metric_best:.6f} --> {metric:.6f}). Saving model ...')\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "            metric_best = metric\n",
    "\n",
    "        # Save Last\n",
    "        if not DEBUG:\n",
    "            torch.save(\n",
    "                {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scaler_state_dict': scaler.state_dict() if scaler else None,\n",
    "                    'score_best': metric_best,\n",
    "                },\n",
    "                model_file.replace('_best', '_last')\n",
    "            )\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-02T09:38:01.421342Z",
     "iopub.status.idle": "2023-07-02T09:38:01.422053Z",
     "shell.execute_reply": "2023-07-02T09:38:01.421836Z",
     "shell.execute_reply.started": "2023-07-02T09:38:01.421814Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-02T09:38:01.423314Z",
     "iopub.status.idle": "2023-07-02T09:38:01.423999Z",
     "shell.execute_reply": "2023-07-02T09:38:01.423782Z",
     "shell.execute_reply.started": "2023-07-02T09:38:01.423761Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available on this system.\")\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "else:\n",
    "    print(\"CUDA is not available on this system.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-02T09:38:01.425339Z",
     "iopub.status.idle": "2023-07-02T09:38:01.426130Z",
     "shell.execute_reply": "2023-07-02T09:38:01.425887Z",
     "shell.execute_reply.started": "2023-07-02T09:38:01.425862Z"
    }
   },
   "outputs": [],
   "source": [
    "run(0)\n",
    "run(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
